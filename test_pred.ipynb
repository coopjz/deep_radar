{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7042489 parameters, 0 gradients, 15.9 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "from radar_class.armor_predictor import YoloV5\n",
    "import cv2\n",
    "import torch\n",
    "from yolov5.models.common import DetectMultiBackend\n",
    "from yolov5.utils.augmentations import (Albumentations, augment_hsv, classify_albumentations, classify_transforms, copy_paste,\n",
    "                                        letterbox, mixup, random_perspective)\n",
    "import numpy as np\n",
    "from yolov5.utils.general import (LOGGER, Profile, check_file, check_img_size, check_imshow, colorstr, cv2,\n",
    "                                  increment_path, non_max_suppression, print_args, scale_boxes, strip_optimizer, xyxy2xywh)\n",
    "# net = YoloV5()\n",
    "net =  DetectMultiBackend(\"/home/cooper/Documents/RM2023-Deep-Radar/yolov5/runs/train/car_30011/weights/best.pt\",\n",
    "                                        device=torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"), data='yolov5/data/car.yaml')\n",
    "net1 = DetectMultiBackend('/home/cooper/Documents/RM2023-Deep-Radar/yolov5/armor.pt',device=torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"), data='yolov5/data/armor.yaml')\n",
    "img0= cv2.imread('/home/cooper/Documents/RM2023-Deep-Radar/dataset/combined/test/images/field_000405.jpg')\n",
    "\n",
    "img_preds, car_locations = [], []\n",
    "#show image\n",
    "img = img0.copy()\n",
    "img = letterbox(img, [640, 640], stride=32, auto=False)[\n",
    "                0]  # padded resize\n",
    "img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "img = np.ascontiguousarray(img)  # contiguous\n",
    "img = torch.from_numpy(img).to(torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\")).float()\n",
    "img = img / 255\n",
    "if len(img.shape) == 3:\n",
    "    img = img[None]  # expand for batch dim\n",
    "ori_shape = (img0.shape[0], img0.shape[1], img0.shape[2])\n",
    "\n",
    "pred= net(img)\n",
    "pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45)\n",
    "pred[0][:, :4] = scale_boxes(\n",
    "    img.shape[2:], pred[0][:, :4], ori_shape).round()\n",
    "\n",
    "car_pred_per_img = []\n",
    "armor_pred_per_img = []\n",
    "car_bbox_pre_img = []\n",
    "\n",
    "ori_car_pred_per_img = []\n",
    "ori_armor_pred_per_img = []\n",
    "armor_num_per_img = []\n",
    "if pred[0].shape[0] == 0:\n",
    "    img_preds.append([])\n",
    "    car_locations.append([None, None])\n",
    "\n",
    "for i in range(pred[0].shape[0]):\n",
    "    if (pred[0][i][5] == 0):\n",
    "        ori_car_pred_per_img.append(pred[0][i])\n",
    "\n",
    "        car_x1 = pred[0][i][0].cpu().numpy().astype(np.uint16) \n",
    "        car_y1 = pred[0][i][1].cpu().numpy().astype(np.uint16)\n",
    "        car_x2 = pred[0][i][2].cpu().numpy().astype(np.uint16)\n",
    "        car_y2 = pred[0][i][3].cpu().numpy().astype(np.uint16)\n",
    "        car_acc = pred[0][i][4].cpu().numpy().astype(np.uint16)\n",
    "\n",
    "        # predict the number of armor\n",
    "        # crop as x1+1/4*width, x2-1/4*width for the armor_area to remove the LEDs for armor\n",
    "\n",
    "        ori_car_area = img0[car_y1:car_y2,\n",
    "                                car_x1:car_x2]\n",
    "        \n",
    "        car_area = ori_car_area.copy()\n",
    "\n",
    "        cv2.imwrite('test_armor.png', ori_car_area*255)\n",
    "        cv2.imwrite('test_ori_armor.png', ori_car_area)\n",
    "\n",
    "        # input is row: 20 col: 28 format: CV_8UC1\n",
    "        ori_car_area_grey = (cv2.cvtColor(car_area, cv2.COLOR_BGR2GRAY) /\n",
    "                255.0).astype(np.float32)\n",
    "\n",
    "        car_area_img = letterbox(car_area, [640, 640], stride=32, auto=False)[\n",
    "            0]  # padded resize\n",
    "        car_area_img = car_area_img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "        car_area_img = np.ascontiguousarray(car_area_img)  # contiguous\n",
    "        car_area_img = torch.from_numpy(car_area_img).to(torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\")).float()\n",
    "        car_area_img = car_area_img / 255\n",
    "        if len(car_area_img.shape) == 3:\n",
    "            car_area_img = car_area_img[None]  # expand for batch dim\n",
    "\n",
    "        # torch.Size([1, 3, 448, 640])\n",
    "        pred_armor = net1(car_area_img)\n",
    "        # output of the pred: shape (b, N, 6)\n",
    "        # x1, y1, x2, y2, acc, class\n",
    "\n",
    "        pred_armor = non_max_suppression(pred_armor, conf_thres=0.25, iou_thres=0.45)\n",
    "        \n",
    "        pred_armor[0][:, :4] = scale_boxes(\n",
    "            car_area_img.shape[2:], pred_armor[0][:, :4], ori_shape).round()\n",
    "        \n",
    "\n",
    "        for k in range(pred_armor[0].shape[0]):\n",
    "            armor_num_per_img.append(pred_armor[0][k][5])\n",
    "            ori_armor_pred_per_img.append(pred_armor[0][k])\n",
    "            armor_x1 = pred_armor[0][k][0].cpu().numpy().astype(np.uint16)\n",
    "            armor_y1 = pred_armor[0][k][1].cpu().numpy().astype(np.uint16)\n",
    "            armor_x2 = pred_armor[0][k][2].cpu().numpy().astype(np.uint16)\n",
    "            armor_y2 = pred_armor[0][k][3].cpu().numpy().astype(np.uint16)\n",
    "            armor_acc = pred_armor[0][k][4].cpu().numpy().astype(np.uint16)\n",
    "\n",
    "#draw the bbox of armor\n",
    "            cv2.namedWindow('image', cv2.WINDOW_NORMAL)\n",
    "            cv2.rectangle(img0, (782, 1882),\n",
    "                        (1497, 2160), (0, 0, 255), 2)\n",
    "            #show the image in proper size\n",
    "            cv2.imshow('image', img0)\n",
    "            cv2.waitKey(0)\n",
    "                        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
